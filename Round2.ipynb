{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYfL066PVjJ3"
      },
      "source": [
        "# importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SfNYJzp4VjJ8"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import math\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNZcx9XQVjJ_"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "knwh5qrmVjJ_"
      },
      "outputs": [],
      "source": [
        "# remove useless text from the data\n",
        "def remove_useless_text(text):\n",
        "    text = re.sub(r'\\n_CHAPTER *[A-Z]*[A-Z]._|\\nCHAPTER *[A-Z]*[A-Z].|\\n_([\\s\\S]*?)_|\\n([\\s\\S]*?)\\*\\*\\* START OF THE PROJECT ([\\s\\S]*?)\\*\\*\\*', ' ', text)\n",
        "    text = re.sub(r'\\n\\*\\*\\* END OF THE PROJECT ([\\s\\S]*)',' ',text)\n",
        "    return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HRHyzfyLVjKA"
      },
      "outputs": [],
      "source": [
        "# reading text from the book and told\n",
        "with open('pg66677.txt', 'r',encoding='utf-8') as f:\n",
        "    text_book1 = ''.join(f.readlines())\n",
        "    \n",
        "with open('pg66678.txt', 'r',encoding='utf-8') as f:\n",
        "    text_book2 = ''.join(f.readlines())\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RSx4cqv1VjKB"
      },
      "outputs": [],
      "source": [
        "text_book1 = remove_useless_text(text_book1)\n",
        "text_book2= remove_useless_text(text_book2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Owpz9i9cVjKC"
      },
      "outputs": [],
      "source": [
        "# converting all text to lower case and removing any link\n",
        "def to_lower(text):\n",
        "    text = text.lower()\n",
        "    re.sub(r\"http\\S+\", \"\", text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Wj_va4VEVjKE"
      },
      "outputs": [],
      "source": [
        "text_book1 = to_lower(text_book1)\n",
        "text_book2=to_lower(text_book2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0qavg7DxVjKF"
      },
      "outputs": [],
      "source": [
        "#converting short forms to full forms\n",
        "def conversion(text):\n",
        "    \n",
        "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
        "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'s\", \" is\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'m\", \" am\", text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6vdwGWgyVjKH"
      },
      "outputs": [],
      "source": [
        "text_book1 = conversion(text_book1)\n",
        "text_book2= conversion(text_book2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LjRj9qUUVjKI"
      },
      "outputs": [],
      "source": [
        "# removing all the puntuations from the text\n",
        "def remove_punctuations(text):\n",
        "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text) \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mMEYhyljVjKI"
      },
      "outputs": [],
      "source": [
        "text_book1= remove_punctuations(text_book1)\n",
        "text_book2=remove_punctuations(text_book2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6rHePMzVjKJ"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEQ5CXboVjKK",
        "outputId": "83578914-3fcd-4b00-9a87-a03c4d49c121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# splitting text into words\n",
        "def tokonize_word(text):\n",
        "    words = word_tokenize(text)\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ttdErrtiVjKL"
      },
      "outputs": [],
      "source": [
        "words_book1 = tokonize_word(text_book1)\n",
        "words_book2 = tokonize_word(text_book2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Round1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
